{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f6db9d3-5763-4473-b87f-3ce0972392f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583c9847-6334-43f4-bd7b-4d3e7d09fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"bike_data\"  # Root directory with all month folders\n",
    "output_file = \"citibike_hourly_summary_2020_2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d2cc079-c041-487c-a796-00a017e898bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(folder_name):\n",
    "    return folder_name.split(\"-\")[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f97bf9c-27cb-4830-befa-d5fe1fb0fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(file_path, expected_month):\n",
    "    chunks = pd.read_csv(file_path, chunksize=100_000, low_memory=False, parse_dates=['started_at', 'ended_at'])\n",
    "    results = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Ensure datetime conversion\n",
    "        chunk = chunk.dropna(subset=['started_at', 'ended_at'])\n",
    "        chunk['started_at'] = pd.to_datetime(chunk['started_at'], errors='coerce')\n",
    "        chunk['ended_at'] = pd.to_datetime(chunk['ended_at'], errors='coerce')\n",
    "        chunk = chunk.dropna(subset=['started_at', 'ended_at'])\n",
    "\n",
    "        # Filter to rides that start and end in the correct month\n",
    "        chunk = chunk[\n",
    "            (chunk['started_at'].dt.strftime(\"%Y%m\") == expected_month) &\n",
    "            (chunk['ended_at'].dt.strftime(\"%Y%m\") == expected_month)\n",
    "        ]\n",
    "\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # Calculate ride duration and round to hour\n",
    "        chunk['ride_duration_min'] = (chunk['ended_at'] - chunk['started_at']).dt.total_seconds() / 60\n",
    "        chunk['hour'] = chunk['started_at'].dt.floor('h')\n",
    "\n",
    "        # Group by hour\n",
    "        hourly = chunk.groupby('hour').agg(\n",
    "            ride_count=('ride_id', 'count'),\n",
    "            avg_ride_duration_min=('ride_duration_min', 'mean')\n",
    "        ).reset_index()\n",
    "\n",
    "        results.append(hourly)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True) if results else pd.DataFrame(columns=['hour', 'ride_count', 'avg_ride_duration_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdbee22d-db72-48d6-a2e1-74d42275fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97712450-721c-4e90-98c8-62fa1a438b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Processing month: 202001 (202001-citibike-tripdata)\n",
      "  ğŸ“„ File: 202001-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202001-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202002 (202002-citibike-tripdata)\n",
      "  ğŸ“„ File: 202002-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202002-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202003 (202003-citibike-tripdata)\n",
      "  ğŸ“„ File: 202003-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202003-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202004 (202004-citibike-tripdata)\n",
      "  ğŸ“„ File: 202004-citibike-tripdata_1.csv\n",
      "ğŸ“ Processing month: 202005 (202005-citibike-tripdata)\n",
      "  ğŸ“„ File: 202005-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202005-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202006 (202006-citibike-tripdata)\n",
      "  ğŸ“„ File: 202006-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202006-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202007 (202007-citibike-tripdata)\n",
      "  ğŸ“„ File: 202007-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202007-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202007-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202008 (202008-citibike-tripdata)\n",
      "  ğŸ“„ File: 202008-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202008-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202008-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202009 (202009-citibike-tripdata)\n",
      "  ğŸ“„ File: 202009-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202009-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202009-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202010 (202010-citibike-tripdata)\n",
      "  ğŸ“„ File: 202010-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202010-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202010-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202011 (202011-citibike-tripdata)\n",
      "  ğŸ“„ File: 202011-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202011-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202012 (202012-citibike-tripdata)\n",
      "  ğŸ“„ File: 202012-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202012-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202101 (202101-citibike-tripdata)\n",
      "  ğŸ“„ File: 202101-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202101-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202102 (202102-citibike-tripdata)\n",
      "  ğŸ“„ File: 202102-citibike-tripdata_1.csv\n",
      "ğŸ“ Processing month: 202103 (202103-citibike-tripdata)\n",
      "  ğŸ“„ File: 202103-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202103-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202104 (202104-citibike-tripdata)\n",
      "  ğŸ“„ File: 202104-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202104-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202104-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202105 (202105-citibike-tripdata)\n",
      "  ğŸ“„ File: 202105-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202105-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202105-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202106 (202106-citibike-tripdata)\n",
      "  ğŸ“„ File: 202106-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202106-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202106-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202106-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202107 (202107-citibike-tripdata)\n",
      "  ğŸ“„ File: 202107-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202107-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202107-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202107-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202108 (202108-citibike-tripdata)\n",
      "  ğŸ“„ File: 202108-citibike-tripdata_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/3rn3swsn3m10f02c6cqx2fq00000gn/T/ipykernel_24059/1737364568.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“„ File: 202108-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202108-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202108-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202109 (202109-citibike-tripdata)\n",
      "  ğŸ“„ File: 202109-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202109-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202109-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202109-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202110 (202110-citibike-tripdata)\n",
      "  ğŸ“„ File: 202110-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202110-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202110-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202110-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202111 (202111-citibike-tripdata)\n",
      "  ğŸ“„ File: 202111-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202111-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202111-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202112 (202112-citibike-tripdata)\n",
      "  ğŸ“„ File: 202112-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202112-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202201 (202201-citibike-tripdata)\n",
      "  ğŸ“„ File: 202201-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202201-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202202 (202202-citibike-tripdata)\n",
      "  ğŸ“„ File: 202202-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202202-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202203 (202203-citibike-tripdata)\n",
      "  ğŸ“„ File: 202203-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202203-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202204 (202204-citibike-tripdata)\n",
      "  ğŸ“„ File: 202204-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202204-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202204-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202205 (202205-citibike-tripdata)\n",
      "  ğŸ“„ File: 202205-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202205-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202205-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202206 (202206-citibike-tripdata)\n",
      "  ğŸ“„ File: 202206-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202206-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202206-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202206-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202207 (202207-citibike-tripdata)\n",
      "  ğŸ“„ File: 202207-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202207-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202207-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202207-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202208 (202208-citibike-tripdata)\n",
      "  ğŸ“„ File: 202208-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202208-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202208-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202208-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202209 (202209-citibike-tripdata)\n",
      "  ğŸ“„ File: 202209-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202209-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202209-citibike-tripdata_3.csv\n",
      "  ğŸ“„ File: 202209-citibike-tripdata_4.csv\n",
      "ğŸ“ Processing month: 202210 (202210-citibike-tripdata)\n",
      "  ğŸ“„ File: 202210-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202210-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202210-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202211 (202211-citibike-tripdata)\n",
      "  ğŸ“„ File: 202211-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202211-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202211-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202212 (202212-citibike-tripdata)\n",
      "  ğŸ“„ File: 202212-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202212-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202301 (202301-citibike-tripdata)\n",
      "  ğŸ“„ File: 202301-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202301-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202302 (202302-citibike-tripdata)\n",
      "  ğŸ“„ File: 202302-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202302-citibike-tripdata_2.csv\n",
      "ğŸ“ Processing month: 202303 (202303-citibike-tripdata)\n",
      "  ğŸ“„ File: 202303-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202303-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202303-citibike-tripdata_3.csv\n",
      "ğŸ“ Processing month: 202304 (202304-citibike-tripdata)\n",
      "  ğŸ“„ File: 202304-citibike-tripdata_1.csv\n",
      "  ğŸ“„ File: 202304-citibike-tripdata_2.csv\n",
      "  ğŸ“„ File: 202304-citibike-tripdata_3.csv\n"
     ]
    }
   ],
   "source": [
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    expected_month = extract_month(folder_name)\n",
    "    print(f\"ğŸ“ Processing month: {expected_month} ({folder_name})\")\n",
    "\n",
    "    # Get all CSVs inside this folder matching *_citibike-tripdata_*.csv\n",
    "    csv_files = sorted(glob.glob(os.path.join(folder_path, f\"{expected_month}-citibike-tripdata_*.csv\")))\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        print(f\"  ğŸ“„ File: {os.path.basename(file_path)}\")\n",
    "        try:\n",
    "            df = process_csv(file_path, expected_month)\n",
    "            if not df.empty:\n",
    "                all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3daff888-c469-4966-adae-ec06fa7ebd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Done! Saved to: citibike_hourly_summary_2020_2023.csv\n"
     ]
    }
   ],
   "source": [
    "if all_data:\n",
    "    combined = pd.concat(all_data, ignore_index=True)\n",
    "    # Aggregate again in case same hour appears in multiple files\n",
    "    final = combined.groupby('hour').agg(\n",
    "        ride_count=('ride_count', 'sum'),\n",
    "        avg_ride_duration_min=('avg_ride_duration_min', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    final.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Done! Saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data was aggregated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71b711f5-3b94-4a2b-80bf-dcfd35d4b1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "citibike_df = pd.read_csv(\"citibike_hourly_summary_2020_2023.csv\", parse_dates=[\"time\"])\n",
    "weather_df = pd.read_csv(\"weather_data/new_york_weather_2020_2023.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    citibike_df,\n",
    "    weather_df,\n",
    "    on=\"time\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "merged_df.to_csv(\"citibike_weather_merged_2020_2023.csv\", index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c0aeecd-c1e9-447a-819a-457dcfde8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"citibike_weather_merged_2020_2023.csv\", parse_dates=[\"time\"])\n",
    "df2 = pd.read_csv(\"citibike_hourly_with_weather_2023_2025.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "combined_df = pd.concat([df1, df2], ignore_index = True)\n",
    "\n",
    "combined_df.sort_values(by=\"time\", inplace=True)\n",
    "\n",
    "combined_df.to_csv(\"citibike_weather_merged_2020_to_2025.csv\", index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb542ff-336c-4174-bce5-33b1b54b51f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
